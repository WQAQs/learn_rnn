1.code:
    class Model(nn.Module):
        def __init__(self, input_size, output_size, hidden_dim, n_layers):
            super(Model, self).__init__()

            # Defining some parameters
            self.hidden_dim = hidden_dim
            self.n_layers = n_layers

            # Defining the layers
            # RNN Layer
            self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)  #batch_first – If True, then the input and output tensors are provided as
                                                                                    # (batch, seq, feature). Default: False
            # Fully connected layer
            self.fc = nn.Linear(hidden_dim, output_size)

        def forward(self, x):
            batch_size = x.size(0)

            # Initializing hidden state for first input using method defined below
            hidden = self.init_hidden(batch_size)

            # Passing in the input and hidden state into the model and obtaining outputs
            out, hidden = self.rnn(x, hidden)

            # Reshaping the outputs such that it can be fit into the fully connected layer
            out = out.contiguous().view(-1, self.hidden_dim)
            out = self.fc(out)

            return out, hidden
            
    for epoch in range(1, n_epochs + 1):
        optimizer.zero_grad()  # Clears existing gradients from previous epoch
        input_seq=input_seq.cuda()
        output, hidden = model(input_seq)
        target_res = target_seq.view(-1).long()
        loss = criterion(output, target_res)
        loss.backward()  # Does backpropagation and calculates gradients
        optimizer.step()  # Updates the weights accordingly

        if epoch % 10 == 0:
            print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')
            print("Loss: {:.4f}".format(loss.item()))、


2.arguments and config：

    text = ['hey how are you',
            'good i am fine',
            'A simple loop that',
            'list of sentences',
            'Creating another dictionary',
            'Join all the sentences together']

    Input Sequence: hey how are you               
    Target Sequence: ey how are you                
    Input Sequence: good i am fine                
    Target Sequence: ood i am fine                 
    Input Sequence: A simple loop that            
    Target Sequence:  simple loop that             
    Input Sequence: list of sentences             
    Target Sequence: ist of sentences              
    Input Sequence: Creating another dictionary   
    Target Sequence: reating another dictionary    
    Input Sequence: Join all the sentences togethe
    Target Sequence: oin all the sentences together

    dict_size = 23, seq_len = 30, batch_size = 6, hidden_dim = 12
    model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)
    int2char = <class 'dict'>: {0: 'd', 1: 'r', 2: 'l', 3: 'g', 4: 'n', 5: ' ', 6: 'A', 7: 'a', 8: 'u', 9: 'C', 
    10: 'o', 11: 'h', 12: 'm', 13: 'p', 14: 'c', 15: 'e', 16: 's', 17: 'J', 18: 'y', 19: 't', 20: 'f', 21: 'i', 22: 'w'}

3.analysis and discussion 
3.1 breakpoint in ：
    (1) row 36
    arguments shape list:
        target_seq      torch.Size([6, 30])
        target_res      torch.Size([180])
        input_seq       torch.Size([6, 30, 23])
        output          torch.Size([180, 23])
        hidden          torch.Size([1, 6, 12])
3.2.founds:
    (1) it's ok to only one-hot-encode our input sequence, but not one-hot-encode our target sequence,
    where in "loss = criterion(output, target_res)" with “criterion = nn.CrossEntropyLoss()”
    target_res's shape is torch.Size([180]), output's shape is torch.Size([180, 23])
        
        output 
            shape: torch.Size([180, 23])
            value :
            tensor([[ 0.0267,  0.0133, -0.1456,  ..., -0.2715,  0.1818,  0.2227],
                    [ 0.1602,  0.1717, -0.2358,  ..., -0.2506,  0.3003,  0.1452],
                    [ 0.1351,  0.1842, -0.1728,  ..., -0.3248,  0.2085,  0.0306],
                    ...,
                    [-0.0935,  0.2828, -0.4149,  ..., -0.3170,  0.5731,  0.1125],
                    [ 0.0604, -0.0095, -0.2237,  ..., -0.2486,  0.3030,  0.1371],
                    [ 0.1854,  0.2441, -0.2994,  ..., -0.2577,  0.3666,  0.1944]],
                device='cuda:0', grad_fn=<AddmmBackward>)
    
        target_res 
            shape: torch.Size([180])
            value:
            tensor([15, 18,  5, 11, 10, 22,  5,  7,  1, 15,  5, 18, 10,  8,  5,  5,  5,  5,
                    5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 10, 10,  0,  5, 21,  5,
                    7, 12,  5, 20, 21,  4, 15,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,
                    5,  5,  5,  5,  5,  5,  5, 16, 21, 12, 13,  2, 15,  5,  2, 10, 10, 13,
                    5, 19, 11,  7, 19,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,
                    21, 16, 19,  5, 10, 20,  5, 16, 15,  4, 19, 15,  4, 14, 15, 16,  5,  5,
                    5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  1, 15,  7, 19, 21,  4,
                    3,  5,  7,  4, 10, 19, 11, 15,  1,  5,  0, 21, 14, 19, 21, 10,  4,  7,
                    1, 18,  5,  5,  5,  5, 10, 21,  4,  5,  7,  2,  2,  5, 19, 11, 15,  5,
                    16, 15,  4, 19, 15,  4, 14, 15, 16,  5, 19, 10,  3, 15, 19, 11, 15,  1])

        in docs:
            input (Tensor) : :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`
                    in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \geq 1`
                    in the case of K-dimensional loss.
            target (Tensor) : :math:`(N)` where each value is :math:`0 \leq \text{targets}[i] \leq C-1`,
                    or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \geq 1` for
                    K-dimensional loss.

4. Problems in RNN Ble Regression Location:
    4.1. Input_data shape ?  what's the data of one sample ?
        (1)
            (n, time_stamps, ibeacon_dim)
            n: indicates there are n samples in train set 
            time_stamps: indicates the number of time_stamps in one sample
            ibeacon_dim: indicates the number of ibeacons collected over a short period of time choosen as the valid features.
                        So, at time_stamp Ti (0 < i < time_stamps) a vector of size ibeacon_dim is input into the model.
        (2)
            The data of one sample is the data collected over a rational period of time (eg. no more than 4 seconds),
            So in this RNN model, one sample data's shape is (time_stamps, ibeacon_dim).


    4.2. How to difine the model's hyperameters?
        input_size: ibeacon_dim
        output_size: 2 (indicates the x, y coordinates)
        hidden_dim: 12 (it's up to you,you can determine it's value)
        n_layers: 1 (it's up to you,you can determine it's value)